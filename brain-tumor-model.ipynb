{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-21T17:28:12.683675Z","iopub.execute_input":"2023-05-21T17:28:12.684777Z","iopub.status.idle":"2023-05-21T17:28:12.838353Z","shell.execute_reply.started":"2023-05-21T17:28:12.684737Z","shell.execute_reply":"2023-05-21T17:28:12.837427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving model checkpoints after each epoch\nos.mkdir(\"/kaggle/working/models/2pathcnn_bilstm\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Conv3D, ConvLSTM3D, Reshape, Conv3DTranspose, UpSampling3D, MaxPooling3D, Concatenate, Input\nfrom keras.layers import Bidirectional, BatchNormalization, Dropout, Dense, Flatten, Attention, Add, Activation\nfrom keras.models import Model\nimport keras\nimport matplotlib.pyplot as plt\nfrom keras.metrics import categorical_crossentropy\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam,Adadelta\nfrom glob import glob\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:39:33.808791Z","iopub.execute_input":"2023-05-21T17:39:33.809148Z","iopub.status.idle":"2023-05-21T17:39:34.401794Z","shell.execute_reply.started":"2023-05-21T17:39:33.809118Z","shell.execute_reply":"2023-05-21T17:39:34.400771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get corresponsing Mask id\ndef get_id(path):\n    slice = path.split(\".\")[2]\n    id = slice[len(slice)-1:len(slice)-4:-1]\n\n    return id[-1::-1]","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:39:34.403430Z","iopub.execute_input":"2023-05-21T17:39:34.403775Z","iopub.status.idle":"2023-05-21T17:39:34.409216Z","shell.execute_reply.started":"2023-05-21T17:39:34.403739Z","shell.execute_reply":"2023-05-21T17:39:34.408302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA,IncrementalPCA\ndef pca_preprocessing(sample):\n    #divide into its channels\n    t1ce,t2,flair=sample[:,:,:,0],sample[:,:,:,1],sample[:,:,:,2]\n    t1ce_f=np.reshape(t1ce,(128,128*128))\n    t2_f=np.reshape(t2,(128,128*128))\n    flair_f=np.reshape(flair,(128,128*128))\n    \n    p=PCA()\n    #Get components that explains 99% of the slice\n    #t1ce\n    p.fit(t1ce_f)\n\n    var1=np.cumsum(p.explained_variance_ratio_)*100\n    k1=np.argmax(var1>99)\n    \n    #t2\n    p.fit(t2_f)\n    var2=np.cumsum(p.explained_variance_ratio_)*100\n    k2=np.argmax(var2>99)\n    \n    #flair\n    p.fit(flair_f)\n    var3=np.cumsum(p.explained_variance_ratio_)*100\n    k3=np.argmax(var3>99)\n    \n    #perform pca for k1,k2,k3 components\n    pca_t1ce=PCA(k1)\n    t1ce_t=pca_t1ce.inverse_transform(pca_t1ce.fit_transform(t1ce_f))\n    \n    pca_t2=PCA(k2)\n    t2_t=pca_t2.inverse_transform(pca_r2.fit_transform(t2_f))\n    \n    pca_flair=PCA(k3)\n    flair_t=pca_flair.inverse_transform(pca_flair.fit_transform(flair_f))\n    \n    #rebuild the image\n    t1ceR=np.reshape(t1ce_t,(128,128,128))\n    t2R=np.reshape(t2_t,(128,128,128))\n    flairR=np.reshape(flair_t,(128,128,128))\n    \n    #Stack the channels\n    sample_reduced=np.stack([t1ceR,t2R,flairR])\n    \n    return sample_reduced\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load all helper functions onto notebook\n#Image generator\ndef generate_image(paths):\n    for img_path in paths:\n        example_id = get_id(img_path)\n        sample = np.load(img_path)\n\n        mask = np.load(\"../input/mri-data/Data/Train/masks_reformatted/mask_\"+example_id+\".npy\",\"r\")\n        # reshape mask\n        # mask_reshaped=np.reshape(mask,(128*128*128,4))\n        #pca\n        sample=pca_preprocessing(sample)\n        \n        # Normalization\n        normalized_sample = (sample-np.mean(sample, axis=0))/np.std(sample, axis=0)\n        #normalized_sample=np.round(normalized_sample,3)\n        yield normalized_sample, mask\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:39:34.780034Z","iopub.execute_input":"2023-05-21T17:39:34.781140Z","iopub.status.idle":"2023-05-21T17:39:34.787753Z","shell.execute_reply.started":"2023-05-21T17:39:34.781097Z","shell.execute_reply":"2023-05-21T17:39:34.786749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Batch generator\n\ndef batch_generator(paths, batch_size):\n    while True:\n        image = generate_image(paths)\n\n        img_batch = list()\n        mask_batch = list()\n\n        for sample, mask in image:\n            img_batch.append(sample)\n            mask_batch.append(mask)\n\n            if (len(img_batch) == batch_size):\n                yield np.stack(img_batch, axis=0), np.stack(mask_batch, axis=0)\n                img_batch = []\n                mask_batch = []\n\n        if (len(img_batch) != 0):\n            yield np.stack(img_batch, axis=0), np.stack(mask_batch, axis=0)\n            img_batch = []\n            mask_batch = []","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:39:35.760920Z","iopub.execute_input":"2023-05-21T17:39:35.761958Z","iopub.status.idle":"2023-05-21T17:39:35.769094Z","shell.execute_reply.started":"2023-05-21T17:39:35.761912Z","shell.execute_reply":"2023-05-21T17:39:35.768138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Metrics \nfrom keras.losses import categorical_crossentropy\ndef dice_coef(y_true, y_pred):\n    ytrue_f = keras.backend.flatten(y_true)\n    ypred_f = keras.backend.flatten(y_pred)\n\n    intersection = keras.backend.sum(\n        ytrue_f*ypred_f)\n\n    E = keras.backend.epsilon()\n    dice = (2.*intersection+E)/(keras.backend.sum(ytrue_f)+keras.backend.sum(ypred_f)+E)\n    return dice\n\n\ndef dice_loss(y_true, y_pred):\n    dice_loss = 1-dice_coef(y_true, y_pred)\n    return dice_loss\n\n\ndef overall_loss(y_true, y_pred):\n    loss = (0.5*categorical_crossentropy(y_true, y_pred)) + \\\n        dice_loss(y_true, y_pred)\n    return loss\n\ndef multilabel_loss(y_true,y_pred,m):\n    dice=0\n    for i in range(m):\n        dice+=dice_coef(y_true[:,:,:,i],y_pred[:,:,:,i])\n    return dice\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:39:36.783546Z","iopub.execute_input":"2023-05-21T17:39:36.783893Z","iopub.status.idle":"2023-05-21T17:39:36.795382Z","shell.execute_reply.started":"2023-05-21T17:39:36.783862Z","shell.execute_reply":"2023-05-21T17:39:36.794304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Learning rate scheduler\ndef scheduler(epoch,lr):\n    if(epoch%5==0):\n        return lr*tf.math.exp(-0.1*epoch)\n    else:\n        return lr","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:39:37.702819Z","iopub.execute_input":"2023-05-21T17:39:37.703196Z","iopub.status.idle":"2023-05-21T17:39:37.709275Z","shell.execute_reply.started":"2023-05-21T17:39:37.703146Z","shell.execute_reply":"2023-05-21T17:39:37.708259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add augumentation layers\n#Rotation at random\n\nimport random\nfrom scipy import ndimage\n\n@tf.function\ndef rotate(slice,angle):\n    def srotate(slice,angle):\n        vol=ndimage.rotate(slice,angles,reshape=False)\n        return vol\n    augumentation=tf.numpy_function(srotate,[slice],tf.float32)\n    return augumentation","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auguemtation=tf.keras.Sequential(\n    rotate=tf.keras.Layers.Lambda(lambda x:rotate(x,angle=30))\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2 path CNN model\ndef create_2pathed_shallow():\n    input_layer = Input((128, 128, 128, 3))''\n    # first encoding block\n    # Convolution layers\n    conv1_e_1 = Conv3D(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(input_layer)\n    conv1_e_2 = Conv3D(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv1_e_1)\n    conv1_e_3 = Conv3D(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv1_e_2)\n\n    # Downsample\n    pool1_e_1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(conv1_e_3)\n\n    # Convolution Layers\n    conv1_e_4 = Conv3D(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(pool1_e_1)\n    conv1_e_5 = Conv3D(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv1_e_4)\n    conv1_e_6 = Conv3D(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), strides=1, activation='elu', use_bias=True, bias_initializer='he_normal')(conv1_e_5)\n\n    # Batch normalization to get mean 0 activations\n    batch1 = BatchNormalization()(conv1_e_6)\n\n    # Second encoding block\n    # Convolutions\n    conv2_e_1 = Conv3D(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(input_layer)\n    conv2_e_2 = Conv3D(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv2_e_1)\n    conv2_e_3 = Conv3D(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv2_e_2)\n\n    # Pooling\n    pool2_e_1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(conv2_e_3)\n\n    # Convolutions\n    conv2_e_4 = Conv3D(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(pool2_e_1)\n    conv2_e_5 = Conv3D(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv2_e_4)\n    conv2_e_6 = Conv3D(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv2_e_5)\n\n    batch2 = BatchNormalization()(conv2_e_6)\n\n    # Concatenate\n    path_combined = Concatenate(axis=4)([batch1, batch2])\n\n    # Combined convolutions\n    conv_7 = Conv3D(filters=32, kernel_initializer='he_normal', kernel_size=(3, 3, 3), activation='elu',\n                    strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(path_combined)\n    conv_8 = Conv3D(filters=64, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv_7)\n    conv_9 = Conv3D(filters=128, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(conv_8)\n\n    batch3 = BatchNormalization()(conv_9)\n\n    # Deconvolution\n    d_conv = Conv3DTranspose(filters=128, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, use_bias=True, bias_initializer='he_normal')(batch3)\n    d_conv_1 = Conv3DTranspose(filters=64, kernel_initializer='he_normal', activation='elu',\n                               strides=1, kernel_size=(3, 3, 3), padding='valid', use_bias=True, bias_initializer='he_normal')(d_conv)\n    d_conv_2 = Conv3DTranspose(filters=32, kernel_initializer='he_normal', activation='elu',\n                               strides=1, kernel_size=(3, 3, 3), padding='valid', use_bias=True, bias_initializer='he_normal')(d_conv_1)\n\n    # first decoding block\n    dconv1_e_1 = Conv3DTranspose(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(d_conv_2)\n    dconv1_e_2 = Conv3DTranspose(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(dconv1_e_1)\n    dconv1_e_3 = Conv3DTranspose(filters=16, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(dconv1_e_2)\n\n    upsample_e_1 = UpSampling3D(size=(2, 2, 2))(dconv1_e_3)\n\n    dconv1_e_4 = Conv3DTranspose(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(upsample_e_1)\n    dconv1_e_5 = Conv3DTranspose(filters=8, kernel_initializer='he_normal', kernel_size=(\n        3, 3, 3), activation='elu', strides=1, padding='valid', use_bias=True, bias_initializer='he_normal')(dconv1_e_4)\n\n    batchnorm = BatchNormalization()(dconv1_e_5)\n\n    mask = Conv3DTranspose(filters=4, kernel_initializer='glorot_normal', kernel_size=(\n        3, 3, 3), activation='softmax', strides=1, padding='valid', use_bias=True, bias_initializer='glorot_normal')(batchnorm)\n\n    model = Model(inputs=input_layer, outputs=mask)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:39:39.413475Z","iopub.execute_input":"2023-05-21T17:39:39.414109Z","iopub.status.idle":"2023-05-21T17:39:39.441975Z","shell.execute_reply.started":"2023-05-21T17:39:39.414063Z","shell.execute_reply":"2023-05-21T17:39:39.441080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compute steps per epoch\ndef steps(m,batchsize):\n    return (m+batchsize-1)//batchsize","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:19.605519Z","iopub.execute_input":"2023-05-21T17:55:19.605889Z","iopub.status.idle":"2023-05-21T17:55:19.610108Z","shell.execute_reply.started":"2023-05-21T17:55:19.605858Z","shell.execute_reply":"2023-05-21T17:55:19.609253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Main program\nsample_paths=sorted(glob(\"../input/mri-data/Data/Train/samples_processed/*.npy\"))\nmasks_paths=sorted(glob(\"../input/mri-data/Data/Train/masks_reformatted/*.npy\"))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:20.736858Z","iopub.execute_input":"2023-05-21T17:55:20.737231Z","iopub.status.idle":"2023-05-21T17:55:20.752036Z","shell.execute_reply.started":"2023-05-21T17:55:20.737195Z","shell.execute_reply":"2023-05-21T17:55:20.751117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train-test split\ntrain_sample_paths,test_sample_paths=train_test_split(sample_paths,test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:22.566415Z","iopub.execute_input":"2023-05-21T17:55:22.566838Z","iopub.status.idle":"2023-05-21T17:55:22.576827Z","shell.execute_reply.started":"2023-05-21T17:55:22.566803Z","shell.execute_reply":"2023-05-21T17:55:22.575868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_sample_paths)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:23.815654Z","iopub.execute_input":"2023-05-21T17:55:23.816009Z","iopub.status.idle":"2023-05-21T17:55:23.825961Z","shell.execute_reply.started":"2023-05-21T17:55:23.815978Z","shell.execute_reply":"2023-05-21T17:55:23.825079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traingen=batch_generator(train_sample_paths,8)\ntestgen=batch_generator(test_sample_paths,8)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:25.210315Z","iopub.execute_input":"2023-05-21T17:55:25.211316Z","iopub.status.idle":"2023-05-21T17:55:25.215773Z","shell.execute_reply.started":"2023-05-21T17:55:25.211266Z","shell.execute_reply":"2023-05-21T17:55:25.214873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample,masks=next(testgen)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:13:00.126547Z","iopub.execute_input":"2023-05-21T17:13:00.126906Z","iopub.status.idle":"2023-05-21T17:13:09.041128Z","shell.execute_reply.started":"2023-05-21T17:13:00.126878Z","shell.execute_reply":"2023-05-21T17:13:09.040125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.shape,masks.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:13:17.186582Z","iopub.execute_input":"2023-05-21T17:13:17.186935Z","iopub.status.idle":"2023-05-21T17:13:17.194590Z","shell.execute_reply.started":"2023-05-21T17:13:17.186906Z","shell.execute_reply":"2023-05-21T17:13:17.193536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=create_2pathed_shallow()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:35.466656Z","iopub.execute_input":"2023-05-21T17:55:35.467009Z","iopub.status.idle":"2023-05-21T17:55:38.511279Z","shell.execute_reply.started":"2023-05-21T17:55:35.466979Z","shell.execute_reply":"2023-05-21T17:55:38.510357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:40.225380Z","iopub.execute_input":"2023-05-21T17:55:40.225735Z","iopub.status.idle":"2023-05-21T17:55:40.304927Z","shell.execute_reply.started":"2023-05-21T17:55:40.225707Z","shell.execute_reply":"2023-05-21T17:55:40.304229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_steps=steps(len(train_sample_paths),8)\ntest_steps=steps(len(test_sample_paths),8)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:55:48.816073Z","iopub.execute_input":"2023-05-21T17:55:48.816639Z","iopub.status.idle":"2023-05-21T17:55:48.825929Z","shell.execute_reply.started":"2023-05-21T17:55:48.816596Z","shell.execute_reply":"2023-05-21T17:55:48.824939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n\nopt=tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt,loss=dice_loss,metrics=[dice_coef,categorical_crossentropy,overall_loss,tf.keras.metrics.CategoricalAccuracy()])\n\n#callbacks\nlog_dir = \"/kaggle/working/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\nschedule=tf.keras.callbacks.LearningRateScheduler(scheduler)\nplateau_handler=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1)\nnanterminate=tf.keras.callbacks.TerminateOnNaN()\n#earlystop=tf.keras.callbacks.EarlyStopping(monitor='val_loss')\ncheckpoints=tf.keras.callbacks.ModelCheckpoint(filepath=\"/kaggle/working/models/2pathcnn_bilstm\",save_weights_only=False,save_freq='epoch',save_best_only=True,monitor='dice_coef',mode='max',verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:56:01.888999Z","iopub.execute_input":"2023-05-21T17:56:01.889364Z","iopub.status.idle":"2023-05-21T17:56:02.204551Z","shell.execute_reply.started":"2023-05-21T17:56:01.889328Z","shell.execute_reply":"2023-05-21T17:56:02.203637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:56:03.207002Z","iopub.execute_input":"2023-05-21T17:56:03.207370Z","iopub.status.idle":"2023-05-21T17:56:03.213148Z","shell.execute_reply.started":"2023-05-21T17:56:03.207337Z","shell.execute_reply":"2023-05-21T17:56:03.212293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.test.is_gpu_available()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:56:04.516647Z","iopub.execute_input":"2023-05-21T17:56:04.517034Z","iopub.status.idle":"2023-05-21T17:56:04.528677Z","shell.execute_reply.started":"2023-05-21T17:56:04.517002Z","shell.execute_reply":"2023-05-21T17:56:04.527602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\nsession = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:56:05.921043Z","iopub.execute_input":"2023-05-21T17:56:05.921711Z","iopub.status.idle":"2023-05-21T17:56:05.930259Z","shell.execute_reply.started":"2023-05-21T17:56:05.921674Z","shell.execute_reply":"2023-05-21T17:56:05.929227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#session.close()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:48:24.194890Z","iopub.execute_input":"2023-05-21T16:48:24.195272Z","iopub.status.idle":"2023-05-21T16:48:24.201986Z","shell.execute_reply.started":"2023-05-21T16:48:24.195240Z","shell.execute_reply":"2023-05-21T16:48:24.201062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(traingen,steps_per_epoch=train_steps,epochs=30,validation_data=testgen,validation_steps=test_steps,verbose=1,callbacks=[tensorboard_callback,plateau_handler,schedule,checkpoints,nanterminate])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:56:08.910124Z","iopub.execute_input":"2023-05-21T17:56:08.910676Z","iopub.status.idle":"2023-05-21T21:10:44.806800Z","shell.execute_reply.started":"2023-05-21T17:56:08.910639Z","shell.execute_reply":"2023-05-21T21:10:44.803808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\nplt.title(\"Loss curve for train\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T21:11:02.209869Z","iopub.execute_input":"2023-05-21T21:11:02.210253Z","iopub.status.idle":"2023-05-21T21:11:02.522341Z","shell.execute_reply.started":"2023-05-21T21:11:02.210218Z","shell.execute_reply":"2023-05-21T21:11:02.521415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(\"Loss curve for train\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T21:11:23.926939Z","iopub.execute_input":"2023-05-21T21:11:23.927341Z","iopub.status.idle":"2023-05-21T21:11:24.191032Z","shell.execute_reply.started":"2023-05-21T21:11:23.927308Z","shell.execute_reply":"2023-05-21T21:11:24.190138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_dice_coef'])\nplt.plot(history.history['dice_coef'])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Dice score\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T21:13:50.613795Z","iopub.execute_input":"2023-05-21T21:13:50.614168Z","iopub.status.idle":"2023-05-21T21:13:50.838957Z","shell.execute_reply.started":"2023-05-21T21:13:50.614137Z","shell.execute_reply":"2023-05-21T21:13:50.838048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['categorical_accuracy'])\nplt.plot(history.history['val_categorical_accuracy'])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T21:14:07.965188Z","iopub.execute_input":"2023-05-21T21:14:07.965555Z","iopub.status.idle":"2023-05-21T21:14:08.187207Z","shell.execute_reply.started":"2023-05-21T21:14:07.965523Z","shell.execute_reply":"2023-05-21T21:14:08.186157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['overall_loss'])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Weighted categorical and dice loss\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T21:16:02.863512Z","iopub.execute_input":"2023-05-21T21:16:02.863885Z","iopub.status.idle":"2023-05-21T21:16:03.125069Z","shell.execute_reply.started":"2023-05-21T21:16:02.863849Z","shell.execute_reply":"2023-05-21T21:16:03.124107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}